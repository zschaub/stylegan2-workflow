{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (4.61.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import train\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name of Images Folder in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_set = 'mona-lisa'\n",
    "resolution = 512\n",
    "knum = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(pil_img, crop_width):\n",
    "    \n",
    "    crop = crop_width\n",
    "    \n",
    "    img_width, img_height = pil_img.size\n",
    "    if img_width < crop_width:\n",
    "        crop_width = img_width\n",
    "    if img_height < crop_width:\n",
    "        crop_width = img_height\n",
    "        \n",
    "    a = (img_width - crop_width) // 2\n",
    "    b = (img_height - crop_width) // 2\n",
    "    c = (img_width + crop_width) // 2\n",
    "    d = (img_height + crop_width) // 2\n",
    "        \n",
    "    cropped_image = pil_img.crop((a,b,c,d))\n",
    "    return cropped_image.resize((crop, crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_dir = './images/'\n",
    "save_dir = './tmp/'\n",
    "\n",
    "image_dir = os.path.join(image_dir, image_set)\n",
    "save_dir = os.path.join(save_dir, image_set)\n",
    "\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "else:\n",
    "    try:\n",
    "        shutil.rmtree(save_dir)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (dir_path, e.strerror))\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    file_extension = os.path.splitext(filename)[-1]\n",
    "    if file_extension != '.jpg' and file_extension != '.png':\n",
    "        print(file_extension)\n",
    "        continue\n",
    "    \n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    image = Image.open(image_path)\n",
    "    mode = image.mode\n",
    "    if str(mode) != 'RGB':\n",
    "        continue\n",
    "    image = crop_center(image, resolution)\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    image.save(save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Loading images from \"./tmp/mona-lisa\"\n",
      "Creating dataset \"./datasets/mona-lisa\"\n",
      "Added 528 images.                       \n"
     ]
    }
   ],
   "source": [
    "!python dataset_tool.py create_from_images \\\n",
    "    ./datasets/{image_set} \\\n",
    "    ./tmp/{image_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 16384,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 16384,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 1.6384\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1\n",
      "    }\n",
      "  },\n",
      "  \"num_gpus\": 4,\n",
      "  \"image_snapshot_ticks\": 50,\n",
      "  \"network_snapshot_ticks\": 50,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"./datasets/mona-lisa\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 512,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"./datasets/mona-lisa\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 512,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 5,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 8,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": 0.05,\n",
      "  \"run_dir\": \"./training-runs/00000-mona-lisa-res512-auto4-kimg5\"\n",
      "}\n",
      "\n",
      "Output directory:  ./training-runs/00000-mona-lisa-res512-auto4-kimg5\n",
      "Training data:     ./datasets/mona-lisa\n",
      "Training length:   5 kimg\n",
      "Resolution:        512\n",
      "Number of GPUs:    4\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 512, 512]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 16, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
      "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
      "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
      "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
      "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
      "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
      "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
      "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
      "G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n",
      "G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
      "G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n",
      "G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n",
      "---                           ---       ---                 ---             \n",
      "Total                         28700647                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 512, 512)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n",
      "512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
      "512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n",
      "512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n",
      "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
      "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
      "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
      "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
      "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
      "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
      "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
      "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                28982849                                      \n",
      "\n",
      "Exporting sample images...\n",
      "Replicating networks across 4 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "------------------------------------------------------------------------\n",
      "WARNING: Using slow fallback implementation for inter-GPU communication.\n",
      "Please use TensorFlow 1.14 on Linux for optimal training performance.\n",
      "------------------------------------------------------------------------\n",
      "Initializing metrics...\n",
      "Training for 5 kimg...\n",
      "\n",
      "tensorflow-1-15-gpu--ml-p3-8xlarge-17ea97aaf69e14e0f1f5454d7cf3:3118:3356 [0] NCCL INFO NET/Socket : Using [0]veth-app0-2:169.255.255.2<0>\n",
      "tensorflow-1-15-gpu--ml-p3-8xlarge-17ea97aaf69e14e0f1f5454d7cf3:3118:3356 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "\n",
      "tensorflow-1-15-gpu--ml-p3-8xlarge-17ea97aaf69e14e0f1f5454d7cf3:3118:3356 [0] external/nccl_archive/src/misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\n",
      "tick 0     kimg 0.1      time 26m 37s      sec/tick 65.5    sec/kimg 512.04  maintenance 1531.2 gpumem 10.0  augment 0.000\n",
      "Evaluating metrics...\n",
      "network-snapshot-000000        time 2m 57s       fid50k_full 327.3902\n",
      "tick 1     kimg 4.2      time 32m 18s      sec/tick 89.2    sec/kimg 21.78   maintenance 252.1  gpumem 10.0  augment 0.003\n",
      "tick 2     kimg 5.1      time 32m 37s      sec/tick 18.7    sec/kimg 20.84   maintenance 0.0    gpumem 10.0  augment 0.004\n",
      "Evaluating metrics...\n",
      "network-snapshot-000005        time 2m 57s       fid50k_full 453.8605\n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "!python train.py --outdir=./training-runs --gpus=4 --res={resolution} --data=./datasets/{image_set} --kimg={knum}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 1.15 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-1.15-gpu-py37-cu110-ubuntu18.04-v8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
